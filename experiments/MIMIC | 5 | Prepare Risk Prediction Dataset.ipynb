{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71efa953",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, \"/data/zeljko/projects/medgpt/\")\n",
    "sys.path.insert(0, \"/data/zeljko/projects/MedCAT/\")\n",
    "\n",
    "os.environ['HF_DATASETS_CACHE'] = \"/data/zeljko/.cache/huggingface\"\n",
    "os.environ['TRANSFORMERS_CACHE'] = \"/data/zeljko/.cache/huggingface\"\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e2bc46",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "import datasets\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from medcat.cat import CAT\n",
    "from datasets import DatasetDict\n",
    "from medgpt.datasets import patient_concept_stream\n",
    "from medgpt.datasets.filters import filter_by_count, filter_by_type\n",
    "from medgpt.datasets.utils import get_embeddings_for_tokens, stream_to_separate_examples, add_to_stream, \\\n",
    "                                  remove_parents_from_stream, bucket_concepts, cleanup_stream, \\\n",
    "                                  split_stream, add_age, get_all_splits, add_ttd, add_position_ids, \\\n",
    "                                  fix_types_for_presence, create_risk_prediction_timelines, create_risk_prediction_timelines_but_better\n",
    "from medgpt.utils.cdb_utils import get_parents_map \n",
    "from medgpt.utils.stream_utils import docs2stream, get_patient_count_per_token, get_token_counts_from_dataset\n",
    "from medgpt.tokenizers.simple_map_tokenizer import SimpleMapTokenizer\n",
    "from medgpt.tokenizers.utils import encode_stream\n",
    "from medgpt.metrics.next_concept_prediction import precision, metrics_data2df, ComputePrecisionHF\n",
    "from medcat.cdb import CDB\n",
    "from medgpt.utils import pickle\n",
    "from transformers import GPT2Config, GPT2LMHeadModel, Trainer, TrainingArguments, AutoTokenizer, pipeline, GPT2Tokenizer, LlamaTokenizerFast, LlamaTokenizer\n",
    "import plotly.express as px\n",
    "import pickle\n",
    "from medgpt.tokenizers.utils import pack_text, create_labels, pack_examples, partial_pack_for_risk, trim_ds\n",
    "\n",
    "from medgpt.config import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a180d92-9694-43d3-9ef1-47afc6ebf81c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = Config(yaml_path='/home/ubuntu/projects/medgpt/configs/mimic-mistral.yaml', \n",
    "                extra_yaml_paths=['/home/ubuntu/projects/medgpt/configs/mimic-seq-len-4096.yaml'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5056d98e-bfcf-48f3-aa56-3a48c173ea79",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.risk_prediction['prompts'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37a6109",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "FORCE = False # If true a lot of things will be rebuilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9f7e3d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "DEVICE = torch.device(config.train.device)\n",
    "# This is internal config, only for this notebook\n",
    "BATCH_SIZE = 1000\n",
    "NUM_PROC = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a5a7fa",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "cat = CAT.load_model_pack(config.path.cat, meta_cat_config_dict={'general': {'device': config.cat.meta.device}})\n",
    "cdb = cat.cdb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3805152b-3e29-4275-ade7-9174c3840ac9",
   "metadata": {},
   "source": [
    "## Split timeline in the middle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0440ea-551f-4404-8af0-973cd3d7f6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only use the test set\n",
    "dataset = datasets.load_from_disk(config.path.dataset.just_before_encoding_dataset_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf8c2d4-ce7f-47b8-9dac-e56ccca0442c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not run unless you are testing stuff\n",
    "#import random\n",
    "#from datasets import Dataset\n",
    "#inds = random.sample([i for i in range(len(dataset['test']))], k=200)\n",
    "#dataset = Dataset.from_dict(dataset['test'][inds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b27fe6f-6a0d-42c9-b24b-22b233849557",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.risk_prediction.prompts, config.risk_prediction.min_past_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2596cb76-1692-400b-86fe-1308fd9e6003",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cui_max_timeline_len = 50\n",
    "dataset = dataset.map(\n",
    "        lambda examples: create_risk_prediction_timelines(examples, prefixes=config.risk_prediction.prompts.to_list(), token_type='T-11', n_risk=1, min_past_length=config.risk_prediction.min_past_length,\n",
    "                                                          max_timeline_len=cui_max_timeline_len), #'<TIME> '), # Requires a space at the end\n",
    "        batched=True,\n",
    "        load_from_cache_file=False,\n",
    "        num_proc=NUM_PROC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696f9be3-9fe5-4cae-ada5-418869b456dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(\n",
    "        lambda examples: cleanup_stream(examples, separator='... ', add_context=config.train.use_context),\n",
    "        batched=True,\n",
    "        load_from_cache_file=False,\n",
    "        num_proc=NUM_PROC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c3f03a-8728-47d2-b922-d23f36260f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(config.path.tokenizer.self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37349b1f-41c4-45f7-b9a8-6bb37c3a7e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(lambda examples: encode_stream(examples, tokenizer), \n",
    "                              batched=True, \n",
    "                              num_proc=NUM_PROC, \n",
    "                              remove_columns=[\"stream\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bf953d-2bfe-4ba0-9d48-7bed672ee066",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = dataset.remove_columns(['patient_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5411f15b-2fe4-4554-b000-f54e01936549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test set is only trimming\n",
    "dataset['test'] = dataset['test'].map(\n",
    "    lambda examples: trim_ds(examples, max_len=config.train.max_timeline_len),\n",
    "    batched=True,\n",
    "    batch_size=1000,\n",
    "    num_proc=1,\n",
    ")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3c10d1-29bb-4e5d-b5d3-1b16c43767f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "type_names = []\n",
    "for time, text in config.risk_prediction.prompts.to_list():\n",
    "    type_names.append(f'risk-{time}-T-11')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd0542f-3334-4d09-b3da-7e578c8fe58e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = dataset.map(\n",
    "    lambda examples: create_labels(examples, config, type_names=type_names, extra_label_ids={tokenizer.eos_token_id}),\n",
    "    batched=True,\n",
    "    batch_size=1000,\n",
    "    num_proc=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb9637b-2b6d-425e-bc8f-17e63d3013e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "c = dataset['train'][0]\n",
    "tkns = tokenizer.convert_ids_to_tokens(c['input_ids'])\n",
    "print(len(tkns))\n",
    "for i in range(len(c['input_ids'])):\n",
    "    print(\"{:15} {:7} {:15} {:20} {} {}\".format(tkns[i], c['input_ids'][i], c['time'][i], c['token_type'][i], c['labels'][i], cat.cdb.get_name(tkns[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5a5f84-3eca-4ae4-b884-601a77db18fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "c = dataset['test'][4]\n",
    "tkns = tokenizer.convert_ids_to_tokens(c['input_ids'])\n",
    "print(len(tkns))\n",
    "for i in range(len(c['input_ids'])):\n",
    "    print(\"{:15} {:7} {:15} {:20} {}\".format(tkns[i], c['input_ids'][i], c['time'][i], c['token_type'][i], c['labels'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a9c995-c45b-4311-9351-b9c64e4a6826",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb72558b-5c81-4103-a892-d4b1c30e9019",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.save_to_disk(config.path.dataset.prepared_risk_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14d5983-f316-453d-b65f-3cbf6566e6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.path.trained_model_risk"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
