{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827d562f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, \"/data/zeljko/projects/medgpt/\")\n",
    "\n",
    "os.environ['HF_DATASETS_CACHE'] = \"/data/zeljko/.cache/huggingface\"\n",
    "os.environ['TRANSFORMERS_CACHE'] = \"/data/zeljko/.cache/huggingface\"\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cfe8ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "from medgpt.config import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c275456-9ea3-4410-acc2-4659643ac076",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = Config(yaml_path='/home/ubuntu/projects/medgpt/configs/mimic.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720b9be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "for i in range(10):\n",
    "    d = pickle.load(open(f\"{config.path.dataset.annotated_documents}/clean_part_{i}.pickle\", 'rb'))\n",
    "    data.update(d)\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5079a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(config.path.raw_data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d3417c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Limit a char to be repeated at most 3 times\n",
    "    clean_text = re.sub(\"([^0-9])\\\\1{3,}\", \"\\\\1\\\\1\\\\1\", text)\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa374462",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Replace strings in text with CUIs\n",
    "cuis = set()\n",
    "not_exists = set()\n",
    "i = 0\n",
    "for ind, row in df.iterrows():\n",
    "    i += 1\n",
    "    id = str(row.row_id)\n",
    "    if id in data and data[id]:\n",
    "        new_text = row.text\n",
    "        for item in reversed(data[id]['entities']):\n",
    "            cuis.add(item['cui'])\n",
    "            if new_text[item['start']] != ' ' and new_text[item['start'] - 1] != ' ':\n",
    "                #print(id, 'Space')\n",
    "                #print(item['start'], row.text[item['start'] - 10:item['end']], item['cui'], item['name'], '\\n')\n",
    "                new_text = f\"{new_text[0:item['start']]} {item['cui']}{new_text[item['end']:]}\"\n",
    "            else:\n",
    "                new_text = f\"{new_text[0:item['start']]}{item['cui']}{new_text[item['end']:]}\"\n",
    "        # Clean after replacements are done\n",
    "        new_text = clean_text(new_text)\n",
    "        #print(row.text, new_text)\n",
    "        #print(\"*\"*100)\n",
    "        df.iat[ind, 5] = new_text\n",
    "    else:\n",
    "        not_exists.add(id)\n",
    "    if i % 100000 == 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acc55e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cuis), len(not_exists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f4b5dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df[df.row_id == 1245792].text.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52607942",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(cuis, open(config.path.dataset.cuis_in_text, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64aeeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(config.path.dataset.text_with_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605a7820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will remove all columns except text, subject_id, row id and add a column called source = 'MIMIC-III-text'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aed5268",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['chartdate', 'charttime', 'category'], axis=1)\n",
    "df['source'] = 'MIMIC-III-text'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebf56ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split to train test based on subject ID\n",
    "all_subject_ids = list(set(df.subject_id.values))\n",
    "r_inds = random.sample([i for i in range(len(all_subject_ids))], k=len(all_subject_ids))\n",
    "split = int(0.95 * len(all_subject_ids))\n",
    "train_subject_ids = set([all_subject_ids[i] for i in r_inds[0:split]])\n",
    "test_subject_ids = set([all_subject_ids[i] for i in r_inds[split:]])\n",
    "print(len(train_subject_ids), len(test_subject_ids), len(all_subject_ids))\n",
    "assert (len(train_subject_ids) + len(test_subject_ids)) == len(all_subject_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb323df",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask = [True if x in train_subject_ids else False for x in df.subject_id.values]\n",
    "train_df = df[train_mask]\n",
    "\n",
    "test_mask = [True if x in test_subject_ids else False for x in df.subject_id.values]\n",
    "test_df = df[test_mask]\n",
    "\n",
    "print(len(train_df), len(test_df), len(df))\n",
    "assert (len(train_df) + len(test_df)) == len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61ea4e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df.to_csv(config.path.dataset.train_df, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edd1eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv(config.path.dataset.test_df, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02faf6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = \" \".join(train_df.text)\n",
    "test_text = \" \".join(test_df.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b66249",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_text), len(test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065616cd",
   "metadata": {},
   "source": [
    "# Prepare for GPT training\n",
    "\n",
    "This is used if we want to train an LLM on the data, pure LLM on all the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8d7b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Config, GPT2LMHeadModel, Trainer, TrainingArguments, AutoTokenizer, pipeline, GPT2Tokenizer\n",
    "from medgpt.tokenizers.simple_map_tokenizer import SimpleMapTokenizer\n",
    "from medgpt.models.utils import add_cuis_to_model_and_tokenizer\n",
    "from medgpt.tokenizers.utils import pack_text\n",
    "import re\n",
    "import pickle\n",
    "from medcat.cat import CAT\n",
    "import pandas as pd\n",
    "import datasets\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd80344",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_PROC = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5a8649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tokenizer - this tokenizer has to have the codes in it\n",
    "gpt_tokenizer = AutoTokenizer.from_pretrained(config.path.tokenizer.self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9fb721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each csv should have two columns <source>: MIMIC-text, MIMIC-timelines, Wikipedia, ... and <text>: text\n",
    "dataset = datasets.load_dataset('csv', data_files={'train': [config.path.dataset.train_df],\n",
    "                                                   'test': [config.path.dataset.test_df]})\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9616dac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_dataset = dataset.map(lambda examples: gpt_tokenizer(examples['text']), \n",
    "                              batched=True, \n",
    "                              num_proc=NUM_PROC, \n",
    "                              remove_columns=[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e288baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check one example\n",
    "print(gpt_tokenizer.decode(encoded_dataset['train'][7][\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80147058",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_dataset.save_to_disk(config.path.dataset.text_with_codes_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516f8e62-e170-4963-a2bd-af68a94da409",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_dataset_loaded = datasets.load_from_disk(config.path.dataset.text_with_codes_prepared)\n",
    "encoded_dataset_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56844ce-bfc9-4e07-a4db-d1eb153f944c",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_dataset_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85799988-cde7-4db3-bded-c63aa37421a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gpt_tokenizer.decode(encoded_dataset_loaded['train'][7][\"input_ids\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
