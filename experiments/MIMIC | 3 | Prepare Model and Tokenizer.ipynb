{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5dd237f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, \"/data/zeljko/projects/medgpt/\")\n",
    "sys.path.insert(0, \"/data/zeljko/projects/MedCAT/\")\n",
    "\n",
    "os.environ['HF_DATASETS_CACHE'] = \"/data/zeljko/.cache/huggingface\"\n",
    "os.environ['TRANSFORMERS_CACHE'] = \"/data/zeljko/.cache/huggingface\"\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7a81d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import GPT2Config, Trainer, TrainingArguments, AutoTokenizer, pipeline, GPT2Tokenizer, LlamaForCausalLM, AutoModelForCausalLM\n",
    "from medgpt.tokenizers.simple_map_tokenizer import SimpleMapTokenizer\n",
    "from medgpt.models.utils import add_cuis_to_model_and_tokenizer\n",
    "from medgpt.tokenizers.utils import pack_text\n",
    "import re\n",
    "import pickle\n",
    "from medcat.cat import CAT\n",
    "import pandas as pd\n",
    "import datasets\n",
    "import random\n",
    "import math\n",
    "import yaml\n",
    "from medgpt.config import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a105c3-f832-4318-b133-5b68a60c65a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = Config(yaml_path='/home/ubuntu/projects/medgpt/configs/mimic-mistral.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b6dd59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cat = CAT.load_model_pack(config.path.cat, meta_cat_config_dict={'general': {'device': config.cat.meta.device}})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b609e9",
   "metadata": {},
   "source": [
    "## Prepare the model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd389d0-b731-4aca-a8d9-f2be8b8cc86e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(config.model.base_name)\n",
    "_ = model.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a994f448",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(config.model.base_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad28eeec-82cb-44d8-9b32-32845a376ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = pickle.load(open(config.path.dataset.cuis_in_text, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4942ed2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "add_cuis_to_model_and_tokenizer(tokens, tokenizer, cat, model, \n",
    "                                special_tokens = config.tokenizer.special_tokens.to_dict(),\n",
    "                                additional_tokens = config.tokenizer.additional_tokens.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535c4191-e925-4dcc-b937-a16b30cfb46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_embeddings = model.get_input_embeddings().weight.data\n",
    "output_embeddings = model.get_output_embeddings().weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55510bfb-55fb-46d5-99f3-08ee5a0fc8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(input_embeddings), len(output_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2544ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a map so we know what is what in the tokenizer\n",
    "from collections import defaultdict\n",
    "tkn2type = {}\n",
    "tkn_id2type = {}\n",
    "id2tkn = {}\n",
    "token_type2tokens = defaultdict(set)\n",
    "for tkn, id in tokenizer.vocab.items():\n",
    "    id2tkn[id] = tkn\n",
    "    t = 'text'\n",
    "    if tkn.replace('_', '').replace('Ä ', '').isdigit() and len(tkn) < 6: # Small numbers are numbers, others are CUIs; _ is llama, G is gpt\n",
    "        t = 'number'\n",
    "    elif tkn.strip() in cat.cdb.cui2type_ids and cat.cdb.cui2type_ids[tkn.strip()]:\n",
    "        t = list(cat.cdb.cui2type_ids[tkn.strip()])[0]\n",
    "        token_type2tokens[t].add(tkn)\n",
    "    tkn2type[tkn] = t\n",
    "    tkn_id2type[id] = t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f37ae56-8947-4650-a11f-b916ea7e7d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.path.tokenizer.tkn2type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14ffd44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pickle.dump(tkn2type, open(config.path.tokenizer.tkn2type, 'wb'))\n",
    "pickle.dump(tkn_id2type, open(config.path.tokenizer.tkn_id2type, 'wb'))\n",
    "pickle.dump(id2tkn, open(config.path.tokenizer.id2tkn, 'wb'))\n",
    "pickle.dump(token_type2tokens, open(config.path.tokenizer.token_type2tokens, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33c3e85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save model and tokenizer with the new stuff\n",
    "tokenizer.save_pretrained(config.path.tokenizer.self)\n",
    "model.save_pretrained(config.path.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5cd0b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the just saved models\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.path.tokenizer.self)\n",
    "model = AutoModelForCausalLM.from_pretrained(config.path.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fdffe4-cb11-4c40-99ac-b0b6caffc01f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
